{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014876,
     "end_time": "2024-06-03T17:01:07.523093",
     "exception": false,
     "start_time": "2024-06-03T17:01:07.508217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\n",
    "This starter notebook is provided by the Keras team.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014736,
     "end_time": "2024-06-03T17:01:07.580011",
     "exception": false,
     "start_time": "2024-06-03T17:01:07.565275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📚 | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 14.715162,
     "end_time": "2024-06-03T17:01:22.309231",
     "exception": false,
     "start_time": "2024-06-03T17:01:07.594069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei516/anaconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "2024-12-05 13:27:13.806701: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-05 13:27:13.820099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733405233.838493 3387733 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733405233.843921 3387733 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 13:27:13.863212: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "#Avoid Plotly issues\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013868,
     "end_time": "2024-06-03T17:01:22.598204",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.584336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📁 | Dataset Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.020401,
     "end_time": "2024-06-03T17:01:22.63286",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.612459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/llm-classification-finetuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01414,
     "end_time": "2024-06-03T17:01:22.661285",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.647145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📖 | Meta Data \n",
    "\n",
    "The competition dataset comprises user interactions from the ChatBot Arena. In each interaction, a judge presents one or more prompts to two different large language models and then indicates which model provided the more satisfactory response. The training data contains `55,000` rows, with an expected `25,000` rows in the test set.\n",
    "\n",
    "## Files\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `model_[a/b]`: Model identity, present in train.csv but not in test.csv.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "- `winner_model_[a/b/tie]`: Binary columns indicating the judge's selection (ground truth target).\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "\n",
    "> Note that each interaction may have multiple prompts and responses, but this notebook will use only **one prompt per interaction**. You can choose to use all prompts and responses. Additionally, prompts and responses in the dataframe are provided as string-formatted lists, so they need to be converted to literal lists using `eval()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013838,
     "end_time": "2024-06-03T17:01:22.689785",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.675947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 8.625467,
     "end_time": "2024-06-03T17:01:31.32943",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.703963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{BASE_PATH}/train.csv', encoding='utf-8', encoding_errors='replace')\n",
    "df_test = pd.read_csv(f'{BASE_PATH}/test.csv', encoding='utf-8', encoding_errors='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.034633,
     "end_time": "2024-06-03T17:01:31.409034",
     "exception": false,
     "start_time": "2024-06-03T17:01:31.374401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 繪製橫向分組柱狀圖\\nfig = px.bar(combined_data, y=\\'Battle Outcome\\', x=\\'Count\\', color=\\'Category\\',\\n             barmode=\\'group\\', orientation=\\'h\\', title=\"Counts of Battle Outcomes for A, B, and Tie\",\\n             height=600, text_auto=True)\\n\\n# 更新圖表外觀\\nfig.update_layout(yaxis_title=\"Battle Outcome\",\\n                  xaxis_title=\"Count\",\\n                  legend_title=\"Category\")\\n\\n# 顯示圖表\\nfig\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "# 假設 train 是你的 DataFrame\n",
    "# 整理資料：將每個欄位的 value_counts 結果整理成一個 DataFrame\n",
    "data_a = df_train[\"winner_model_a\"].value_counts().reset_index()\n",
    "data_a.columns = ['Battle Outcome', 'Count']\n",
    "data_a['Category'] = 'Model A'\n",
    "\n",
    "data_b = df_train[\"winner_model_b\"].value_counts().reset_index()\n",
    "data_b.columns = ['Battle Outcome', 'Count']\n",
    "data_b['Category'] = 'Model B'\n",
    "\n",
    "data_tie = df_train[\"winner_tie\"].value_counts().reset_index()\n",
    "data_tie.columns = ['Battle Outcome', 'Count']\n",
    "data_tie['Category'] = 'Tie'\n",
    "\n",
    "# 合併所有資料\n",
    "combined_data = pd.concat([data_a, data_b, data_tie], ignore_index=True)\n",
    "\n",
    "# 過濾掉 Battle Outcome 為 0 的數據\n",
    "combined_data = combined_data[combined_data['Battle Outcome'] != 0]\n",
    "\"\"\"\n",
    "# 繪製橫向分組柱狀圖\n",
    "fig = px.bar(combined_data, y='Battle Outcome', x='Count', color='Category',\n",
    "             barmode='group', orientation='h', title=\"Counts of Battle Outcomes for A, B, and Tie\",\n",
    "             height=600, text_auto=True)\n",
    "\n",
    "# 更新圖表外觀\n",
    "fig.update_layout(yaxis_title=\"Battle Outcome\",\n",
    "                  xaxis_title=\"Count\",\n",
    "                  legend_title=\"Category\")\n",
    "\n",
    "# 顯示圖表\n",
    "fig\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015064,
     "end_time": "2024-06-03T17:02:34.293411",
     "exception": false,
     "start_time": "2024-06-03T17:02:34.278347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.032427,
     "end_time": "2024-06-03T17:02:34.341044",
     "exception": false,
     "start_time": "2024-06-03T17:02:34.308617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig = px.bar(counts,\\n             x='LLM',\\n             y='count',\\n             title='Counts of LLMs in the Training Data',\\n             labels={'LLM': 'LLM', 'count': 'Count'},\\n             color='count',\\n             color_continuous_scale='viridis')\\n\\nfig.update_layout(xaxis_tickangle=-45)\\nfig.show()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "model_df = pd.concat([df_train['model_a'], df_train['model_b']])\n",
    "counts = model_df.value_counts().reset_index()\n",
    "counts.columns = ['LLM', 'count']\n",
    "\"\"\"\n",
    "fig = px.bar(counts,\n",
    "             x='LLM',\n",
    "             y='count',\n",
    "             title='Counts of LLMs in the Training Data',\n",
    "             labels={'LLM': 'LLM', 'count': 'Count'},\n",
    "             color='count',\n",
    "             color_continuous_scale='viridis')\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015466,
     "end_time": "2024-06-03T17:02:34.372077",
     "exception": false,
     "start_time": "2024-06-03T17:02:34.356611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 1.475495,
     "end_time": "2024-06-03T17:02:35.895386",
     "exception": false,
     "start_time": "2024-06-03T17:02:34.419891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Is it morally right to try to have a certain p...   \n",
       "1  What is the difference between marriage licens...   \n",
       "2  explain function calling. how would you call a...   \n",
       "3  How can I create a test set for a very rare ca...   \n",
       "4  What is the best way to travel from Tel-Aviv t...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  Function calling is the process of invoking or...   \n",
       "3  Creating a test set for a very rare category c...   \n",
       "4  The best way to travel from Tel Aviv to Jerusa...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  As an AI, I don't have personal beliefs or opi...               1   \n",
       "1  A marriage license and a marriage certificate ...               0   \n",
       "2  Function calling is the process of invoking a ...               0   \n",
       "3  When building a classifier for a very rare cat...               1   \n",
       "4  The best way to travel from Tel-Aviv to Jerusa...               0   \n",
       "\n",
       "   winner_model_b  winner_tie      class_name  class_label  \n",
       "0               0           0  winner_model_a            0  \n",
       "1               1           0  winner_model_b            1  \n",
       "2               0           1      winner_tie            2  \n",
       "3               0           0  winner_model_a            0  \n",
       "4               1           0  winner_model_b            1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Take the first prompt and its associated response\n",
    "df_train[\"prompt\"] = df_train.prompt.map(lambda x: eval(x)[0])\n",
    "df_train[\"response_a\"] = df_train.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "df_train[\"response_b\"] = df_train.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# Label conversion\n",
    "df_train[\"class_name\"] = df_train[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\n",
    "df_train[\"class_label\"] = df_train[\"class_name\"].map({\"winner_model_a\": 0, \"winner_model_b\": 1, \"winner_tie\": 2})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增一個欄位 pairs，list存放兩組 prompt-response pair(string)\n",
    "\n",
    "def make_pairs(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        prompt = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_a = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_b = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    row['pairs'] = [\n",
    "    f\"[PROMPT] {prompt} [SEP] [RESPONSE_A] {response_a}\",  # Response from Model A\n",
    "    f\"[PROMPT] {prompt} [SEP] [RESPONSE_B] {response_b}\"  # Response from Model B\n",
    "]\n",
    "    return row\n",
    "\n",
    "df_train = df_train.apply(make_pairs, axis=1)\n",
    "df_test = df_test.apply(make_pairs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.112531,
     "end_time": "2024-06-03T17:02:36.056818",
     "exception": false,
     "start_time": "2024-06-03T17:02:35.944287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>encode_fail</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>[\"I have three oranges today, I ate an orange ...</td>\n",
       "      <td>[\"You have two oranges today.\"]</td>\n",
       "      <td>[\"You still have three oranges. Eating an oran...</td>\n",
       "      <td>False</td>\n",
       "      <td>[[PROMPT] [\"I have three oranges today, I ate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>[\"You are a mediator in a heated political deb...</td>\n",
       "      <td>[\"Thank you for sharing the details of the sit...</td>\n",
       "      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[[PROMPT] [\"You are a mediator in a heated pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>[\"How to initialize the classification head wh...</td>\n",
       "      <td>[\"When you want to initialize the classificati...</td>\n",
       "      <td>[\"To initialize the classification head when p...</td>\n",
       "      <td>False</td>\n",
       "      <td>[[PROMPT] [\"How to initialize the classificati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0   136060  [\"I have three oranges today, I ate an orange ...   \n",
       "1   211333  [\"You are a mediator in a heated political deb...   \n",
       "2  1233961  [\"How to initialize the classification head wh...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                    [\"You have two oranges today.\"]   \n",
       "1  [\"Thank you for sharing the details of the sit...   \n",
       "2  [\"When you want to initialize the classificati...   \n",
       "\n",
       "                                          response_b  encode_fail  \\\n",
       "0  [\"You still have three oranges. Eating an oran...        False   \n",
       "1  [\"Mr Reddy and Ms Blue both have valid points ...        False   \n",
       "2  [\"To initialize the classification head when p...        False   \n",
       "\n",
       "                                               pairs  \n",
       "0  [[PROMPT] [\"I have three oranges today, I ate ...  \n",
       "1  [[PROMPT] [\"You are a mediator in a heated pol...  \n",
       "2  [[PROMPT] [\"How to initialize the classificati...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.779715,
     "end_time": "2024-06-03T17:02:36.885945",
     "exception": false,
     "start_time": "2024-06-03T17:02:36.10623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 57477/57477 [00:38<00:00, 1498.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# !pip install datasets transformers\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 加载 multilingual-e5-large 的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained('FacebookAI/roberta-base')\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # 確保 pairs 的每個元素分別處理\n",
    "    encoding_a = tokenizer(\n",
    "        [pair[0] for pair in examples['pairs']],  # 取 pairs 中的第一個字串\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512\n",
    "    )\n",
    "    encoding_b = tokenizer(\n",
    "        [pair[1] for pair in examples['pairs']],  # 取 pairs 中的第二個字串\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'input_ids_a': encoding_a['input_ids'],\n",
    "        'attention_mask_a': encoding_a['attention_mask'],\n",
    "        'input_ids_b': encoding_b['input_ids'],\n",
    "        'attention_mask_b': encoding_b['attention_mask'],\n",
    "        'labels': examples['class_label']\n",
    "    }\n",
    "\n",
    "dataset = Dataset.from_pandas(df_train[['pairs','class_label']])\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016189,
     "end_time": "2024-06-03T17:02:36.919019",
     "exception": false,
     "start_time": "2024-06-03T17:02:36.90283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🍽️ | Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 3.390834,
     "end_time": "2024-06-03T17:02:40.326479",
     "exception": false,
     "start_time": "2024-06-03T17:02:36.935645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 145.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function_test(examples):\n",
    "    # 確保 pairs 的每個元素分別處理\n",
    "    encoding_a = tokenizer(\n",
    "        [pair[0] for pair in examples['pairs']],  # 取 pairs 中的第一個字串\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512\n",
    "    )\n",
    "    encoding_b = tokenizer(\n",
    "        [pair[1] for pair in examples['pairs']],  # 取 pairs 中的第二個字串\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'input_ids_a': encoding_a['input_ids'],\n",
    "        'attention_mask_a': encoding_a['attention_mask'],\n",
    "        'input_ids_b': encoding_b['input_ids'],\n",
    "        'attention_mask_b': encoding_b['attention_mask'],\n",
    "    }\n",
    "\n",
    "dataset_test = Dataset.from_pandas(df_test[['pairs']])\n",
    "tokenized_dataset_test = dataset_test.map(preprocess_function_test, batched=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pairs', 'input_ids_a', 'attention_mask_a', 'input_ids_b', 'attention_mask_b'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定張量格式\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids_a', 'attention_mask_a', 'input_ids_b', 'attention_mask_b', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 1.056025,
     "end_time": "2024-06-03T17:02:41.433464",
     "exception": false,
     "start_time": "2024-06-03T17:02:40.377439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dataset_test.set_format(type='torch', columns=['input_ids_a', 'attention_mask_a', 'input_ids_b', 'attention_mask_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 0.024249,
     "end_time": "2024-06-03T17:02:41.510214",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.485965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 創建 DataLoader\n",
    "batch_size = 8\n",
    "train_dataloader = torch.utils.data.DataLoader(tokenized_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(tokenized_dataset_test, batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016686,
     "end_time": "2024-06-03T17:02:41.543394",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.526708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.026326,
     "end_time": "2024-06-03T17:02:41.586658",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.560332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertComparisonModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name='bert-base-uncased'):\n",
    "        super(BertComparisonModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.pooler = nn.Linear(768 * 2, 768)\n",
    "        self.classifier = nn.Linear(768, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        # 分別通過 BERT 模型\n",
    "        output_a = self.bert(input_ids=input_ids_a, attention_mask=attention_mask_a)\n",
    "        output_b = self.bert(input_ids=input_ids_b, attention_mask=attention_mask_b)\n",
    "\n",
    "        # 獲取 [CLS] token 的輸出作為句子嵌入\n",
    "        embedding_a = output_a.last_hidden_state[:, 0, :]  # [batch_size, 768]\n",
    "        embedding_b = output_b.last_hidden_state[:, 0, :]  # [batch_size, 768]\n",
    "\n",
    "        # 將兩個句子的嵌入串接起來\n",
    "        combined_embedding = torch.cat([embedding_a, embedding_b], dim=1) # [batch_size, 768 * 2]\n",
    "        pooled_embedding = torch.tanh(self.pooler(combined_embedding)) # [batch_size, 768]\n",
    "\n",
    "        # 通過分類器獲取最終的預測結果\n",
    "        logits = self.classifier(pooled_embedding) # [batch_size, 3]\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return logits, probs\n",
    "    \n",
    "    def predict(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        logits, probs = self.forward(input_ids_a, attention_mask_a, input_ids_b, attention_mask_b)\n",
    "        return probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultilingualE5ComparisonModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name='intfloat/multilingual-e5-small'):\n",
    "        super(MultilingualE5ComparisonModel, self).__init__()\n",
    "        # 使用 AutoModel 加载预训练模型\n",
    "        self.model = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        \n",
    "        # 动态获取模型的 hidden size\n",
    "        hidden_size = self.model.config.hidden_size\n",
    "        \n",
    "        # 根据模型的 hidden size 创建池化和分类层\n",
    "        self.pooler = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        # 分别通过模型\n",
    "        output_a = self.model(input_ids=input_ids_a, attention_mask=attention_mask_a)\n",
    "        output_b = self.model(input_ids=input_ids_b, attention_mask=attention_mask_b)\n",
    "        \n",
    "        # 获取 [CLS] token 的输出作为句子嵌入\n",
    "        embedding_a = output_a.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        embedding_b = output_b.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        # 将两个句子的嵌入串接起来\n",
    "        combined_embedding = torch.cat([embedding_a, embedding_b], dim=1)  # [batch_size, hidden_size * 2]\n",
    "        pooled_embedding = torch.tanh(self.pooler(combined_embedding))  # [batch_size, hidden_size]\n",
    "        \n",
    "        # 通过分类器获取最终的预测结果\n",
    "        logits = self.classifier(pooled_embedding)  # [batch_size, 3]\n",
    "        probs = self.softmax(logits)\n",
    "        return logits, probs\n",
    "    \n",
    "    def predict(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        with torch.no_grad():\n",
    "            logits, probs = self.forward(input_ids_a, attention_mask_a, input_ids_b, attention_mask_b)\n",
    "            return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ROBERTAComparisonModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name='FacebookAI/roberta-base'):\n",
    "        super(ROBERTAComparisonModel, self).__init__()\n",
    "        # 使用 AutoModel 加载预训练模型\n",
    "        self.model = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        \n",
    "        # 动态获取模型的 hidden size\n",
    "        hidden_size = self.model.config.hidden_size\n",
    "        \n",
    "        # 根据模型的 hidden size 创建池化和分类层\n",
    "        self.pooler = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        # 分别通过模型\n",
    "        output_a = self.model(input_ids=input_ids_a, attention_mask=attention_mask_a)\n",
    "        output_b = self.model(input_ids=input_ids_b, attention_mask=attention_mask_b)\n",
    "        \n",
    "        # 获取 [CLS] token 的输出作为句子嵌入\n",
    "        embedding_a = output_a.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        embedding_b = output_b.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        # 将两个句子的嵌入串接起来\n",
    "        combined_embedding = torch.cat([embedding_a, embedding_b], dim=1)  # [batch_size, hidden_size * 2]\n",
    "        pooled_embedding = torch.tanh(self.pooler(combined_embedding))  # [batch_size, hidden_size]\n",
    "        \n",
    "        # 通过分类器获取最终的预测结果\n",
    "        logits = self.classifier(pooled_embedding)  # [batch_size, 3]\n",
    "        probs = self.softmax(logits)\n",
    "        return logits, probs\n",
    "    \n",
    "    def predict(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        with torch.no_grad():\n",
    "            logits, probs = self.forward(input_ids_a, attention_mask_a, input_ids_b, attention_mask_b)\n",
    "            return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016559,
     "end_time": "2024-06-03T17:02:41.619713",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.603154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-input": false,
    "papermill": {
     "duration": 5.308478,
     "end_time": "2024-06-03T17:02:46.944786",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.636308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ROBERTAComparisonModel(pretrained_model_name='FacebookAI/roberta-base')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 7185/7185 [46:41<00:00,  2.56batch/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 1.1018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  29%|██████████████████████████▊                                                                 | 2092/7185 [13:36<32:57,  2.58batch/s, loss=1.07]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 定義損失函數\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 訓練設定\n",
    "epochs = 3\n",
    "\n",
    "# 假設 train_dataloader 已經定義\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # 使用 tqdm 包裝 DataLoader\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\", unit=\"batch\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids_a = batch['input_ids_a'].to(device)\n",
    "        attention_mask_a = batch['attention_mask_a'].to(device)\n",
    "        input_ids_b = batch['input_ids_b'].to(device)\n",
    "        attention_mask_b = batch['attention_mask_b'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向傳播\n",
    "        logits, probs = model(input_ids_a, attention_mask_a, input_ids_b, attention_mask_b)\n",
    "\n",
    "        # 計算損失\n",
    "        loss = loss_fn(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 更新進度條的描述\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # 反向傳播與更新參數\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.051632,
     "end_time": "2024-06-03T17:02:55.909391",
     "exception": false,
     "start_time": "2024-06-03T17:02:55.857759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"best_model.weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.754041,
     "end_time": "2024-06-03T19:18:30.53816",
     "exception": false,
     "start_time": "2024-06-03T19:18:29.784119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧪 | Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ROBERTAComparisonModel(pretrained_model_name='FacebookAI/roberta-base')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.weights.pt\"))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 6.510153,
     "end_time": "2024-06-03T19:18:39.767367",
     "exception": false,
     "start_time": "2024-06-03T19:18:33.257214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction loop\n",
    "model.eval()  # Set model to evaluation mode\n",
    "test_preds = []  # To store predictions\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids_a = batch['input_ids_a'].to(device)\n",
    "        attention_mask_a = batch['attention_mask_a'].to(device)\n",
    "        input_ids_b = batch['input_ids_b'].to(device)\n",
    "        attention_mask_b = batch['attention_mask_b'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits, probs = model(\n",
    "            input_ids_a=input_ids_a,\n",
    "            attention_mask_a=attention_mask_a,\n",
    "            input_ids_b=input_ids_b,\n",
    "            attention_mask_b=attention_mask_b\n",
    "        )\n",
    "        print(probs)\n",
    "        # Predicted class\n",
    "        preds = probs\n",
    "        test_preds.extend(preds.cpu().numpy())  # Collect predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.768879,
     "end_time": "2024-06-03T19:18:41.329256",
     "exception": false,
     "start_time": "2024-06-03T19:18:40.560377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📬 | Submission\n",
    "\n",
    "Following code will prepare the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.751809,
     "end_time": "2024-06-03T19:18:42.839827",
     "exception": false,
     "start_time": "2024-06-03T19:18:42.088018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the class names directly\n",
    "label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n",
    "class_names = list(label2name.values())\n",
    "\n",
    "# Convert predictions to a list\n",
    "test_preds = np.array(test_preds).tolist()\n",
    "\n",
    "# Assuming `df_test` has an \"id\" column\n",
    "df_test = pd.DataFrame({'id': [1, 2, 3]})  # Example DataFrame for demonstration\n",
    "\n",
    "# Save results\n",
    "sub_df = df_test[[\"id\"]].copy()\n",
    "sub_df[\"winner_model_a\"] = [pred[0] for pred in test_preds]\n",
    "sub_df[\"winner_model_b\"] = [pred[1] for pred in test_preds]\n",
    "sub_df[\"winner_tie\"] = [pred[2] for pred in test_preds]\n",
    "sub_df.to_csv(\"submission.csv\", index=False)  # Save to CSV\n",
    "\n",
    "# Display the first few rows of the saved DataFrame\n",
    "print(sub_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.740084,
     "end_time": "2024-06-03T19:18:44.386408",
     "exception": false,
     "start_time": "2024-06-03T19:18:43.646324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🔭 | Future Directions\n",
    "\n",
    "In this notebook, we've achieved a good score with a small model and modest token length. But there's plenty of room to improve. Here's how:\n",
    "\n",
    "1. Try bigger models like `Deberta-Base` or `Deberta-Small`, or even LLMs like `Gemma`.\n",
    "2. Increase max token length to reduce loss of data.\n",
    "3. Use a five-fold cross-validation and ensemble to make the model robust and get better scores.\n",
    "4. Add augmentation like shuffling response orders for more robust performance.\n",
    "5. Train for more epochs.\n",
    "6. Tune the learning rate scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.830152,
     "end_time": "2024-06-03T19:18:45.950588",
     "exception": false,
     "start_time": "2024-06-03T19:18:45.120436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📌 | Reference\n",
    "\n",
    "* [LLM Science Exam: KerasCore + KerasNLP [TPU]](https://www.kaggle.com/code/awsaf49/llm-science-exam-kerascore-kerasnlp-tpu)\n",
    "* [AES 2.0: KerasNLP Starter](https://www.kaggle.com/code/awsaf49/aes-2-0-kerasnlp-starter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4686,
     "sourceId": 6065,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4687,
     "sourceId": 6066,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 133071,
     "modelInstanceId": 108753,
     "sourceId": 129073,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8265.260972,
   "end_time": "2024-06-03T19:18:50.009067",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-03T17:01:04.748095",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
