{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014876,
     "end_time": "2024-06-03T17:01:07.523093",
     "exception": false,
     "start_time": "2024-06-03T17:01:07.508217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\n",
    "This starter notebook is provided by the Keras team.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014736,
     "end_time": "2024-06-03T17:01:07.580011",
     "exception": false,
     "start_time": "2024-06-03T17:01:07.565275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìö | Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 14.715162,
     "end_time": "2024-06-03T17:01:22.309231",
     "exception": false,
     "start_time": "2024-06-03T17:01:07.594069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei516/anaconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n",
      "2024-12-05 13:27:13.806701: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-05 13:27:13.820099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733405233.838493 3387733 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733405233.843921 3387733 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 13:27:13.863212: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertModel\n",
    "#Avoid Plotly issues\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013868,
     "end_time": "2024-06-03T17:01:22.598204",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.584336",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìÅ | Dataset Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.020401,
     "end_time": "2024-06-03T17:01:22.63286",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.612459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/llm-classification-finetuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01414,
     "end_time": "2024-06-03T17:01:22.661285",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.647145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìñ | Meta Data \n",
    "\n",
    "The competition dataset comprises user interactions from the ChatBot Arena. In each interaction, a judge presents one or more prompts to two different large language models and then indicates which model provided the more satisfactory response. The training data contains `55,000` rows, with an expected `25,000` rows in the test set.\n",
    "\n",
    "## Files\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `model_[a/b]`: Model identity, present in train.csv but not in test.csv.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "- `winner_model_[a/b/tie]`: Binary columns indicating the judge's selection (ground truth target).\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "\n",
    "> Note that each interaction may have multiple prompts and responses, but this notebook will use only **one prompt per interaction**. You can choose to use all prompts and responses. Additionally, prompts and responses in the dataframe are provided as string-formatted lists, so they need to be converted to literal lists using `eval()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013838,
     "end_time": "2024-06-03T17:01:22.689785",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.675947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 8.625467,
     "end_time": "2024-06-03T17:01:31.32943",
     "exception": false,
     "start_time": "2024-06-03T17:01:22.703963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{BASE_PATH}/train.csv', encoding='utf-8', encoding_errors='replace')\n",
    "df_test = pd.read_csv(f'{BASE_PATH}/test.csv', encoding='utf-8', encoding_errors='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.034633,
     "end_time": "2024-06-03T17:01:31.409034",
     "exception": false,
     "start_time": "2024-06-03T17:01:31.374401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Áπ™Ë£ΩÊ©´ÂêëÂàÜÁµÑÊü±ÁãÄÂúñ\\nfig = px.bar(combined_data, y=\\'Battle Outcome\\', x=\\'Count\\', color=\\'Category\\',\\n             barmode=\\'group\\', orientation=\\'h\\', title=\"Counts of Battle Outcomes for A, B, and Tie\",\\n             height=600, text_auto=True)\\n\\n# Êõ¥Êñ∞ÂúñË°®Â§ñËßÄ\\nfig.update_layout(yaxis_title=\"Battle Outcome\",\\n                  xaxis_title=\"Count\",\\n                  legend_title=\"Category\")\\n\\n# È°ØÁ§∫ÂúñË°®\\nfig\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "# ÂÅáË®≠ train ÊòØ‰Ω†ÁöÑ DataFrame\n",
    "# Êï¥ÁêÜË≥áÊñôÔºöÂ∞áÊØèÂÄãÊ¨Ñ‰ΩçÁöÑ value_counts ÁµêÊûúÊï¥ÁêÜÊàê‰∏ÄÂÄã DataFrame\n",
    "data_a = df_train[\"winner_model_a\"].value_counts().reset_index()\n",
    "data_a.columns = ['Battle Outcome', 'Count']\n",
    "data_a['Category'] = 'Model A'\n",
    "\n",
    "data_b = df_train[\"winner_model_b\"].value_counts().reset_index()\n",
    "data_b.columns = ['Battle Outcome', 'Count']\n",
    "data_b['Category'] = 'Model B'\n",
    "\n",
    "data_tie = df_train[\"winner_tie\"].value_counts().reset_index()\n",
    "data_tie.columns = ['Battle Outcome', 'Count']\n",
    "data_tie['Category'] = 'Tie'\n",
    "\n",
    "# Âêà‰ΩµÊâÄÊúâË≥áÊñô\n",
    "combined_data = pd.concat([data_a, data_b, data_tie], ignore_index=True)\n",
    "\n",
    "# ÈÅéÊøæÊéâ Battle Outcome ÁÇ∫ 0 ÁöÑÊï∏Êìö\n",
    "combined_data = combined_data[combined_data['Battle Outcome'] != 0]\n",
    "\"\"\"\n",
    "# Áπ™Ë£ΩÊ©´ÂêëÂàÜÁµÑÊü±ÁãÄÂúñ\n",
    "fig = px.bar(combined_data, y='Battle Outcome', x='Count', color='Category',\n",
    "             barmode='group', orientation='h', title=\"Counts of Battle Outcomes for A, B, and Tie\",\n",
    "             height=600, text_auto=True)\n",
    "\n",
    "# Êõ¥Êñ∞ÂúñË°®Â§ñËßÄ\n",
    "fig.update_layout(yaxis_title=\"Battle Outcome\",\n",
    "                  xaxis_title=\"Count\",\n",
    "                  legend_title=\"Category\")\n",
    "\n",
    "# È°ØÁ§∫ÂúñË°®\n",
    "fig\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015064,
     "end_time": "2024-06-03T17:02:34.293411",
     "exception": false,
     "start_time": "2024-06-03T17:02:34.278347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.032427,
     "end_time": "2024-06-03T17:02:34.341044",
     "exception": false,
     "start_time": "2024-06-03T17:02:34.308617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig = px.bar(counts,\\n             x='LLM',\\n             y='count',\\n             title='Counts of LLMs in the Training Data',\\n             labels={'LLM': 'LLM', 'count': 'Count'},\\n             color='count',\\n             color_continuous_scale='viridis')\\n\\nfig.update_layout(xaxis_tickangle=-45)\\nfig.show()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "model_df = pd.concat([df_train['model_a'], df_train['model_b']])\n",
    "counts = model_df.value_counts().reset_index()\n",
    "counts.columns = ['LLM', 'count']\n",
    "\"\"\"\n",
    "fig = px.bar(counts,\n",
    "             x='LLM',\n",
    "             y='count',\n",
    "             title='Counts of LLMs in the Training Data',\n",
    "             labels={'LLM': 'LLM', 'count': 'Count'},\n",
    "             color='count',\n",
    "             color_continuous_scale='viridis')\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015466,
     "end_time": "2024-06-03T17:02:34.372077",
     "exception": false,
     "start_time": "2024-06-03T17:02:34.356611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 1.475495,
     "end_time": "2024-06-03T17:02:35.895386",
     "exception": false,
     "start_time": "2024-06-03T17:02:34.419891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>Is it morally right to try to have a certain p...</td>\n",
       "      <td>The question of whether it is morally right to...</td>\n",
       "      <td>As an AI, I don't have personal beliefs or opi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>What is the difference between marriage licens...</td>\n",
       "      <td>A marriage license is a legal document that al...</td>\n",
       "      <td>A marriage license and a marriage certificate ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>explain function calling. how would you call a...</td>\n",
       "      <td>Function calling is the process of invoking or...</td>\n",
       "      <td>Function calling is the process of invoking a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>winner_tie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>How can I create a test set for a very rare ca...</td>\n",
       "      <td>Creating a test set for a very rare category c...</td>\n",
       "      <td>When building a classifier for a very rare cat...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>What is the best way to travel from Tel-Aviv t...</td>\n",
       "      <td>The best way to travel from Tel Aviv to Jerusa...</td>\n",
       "      <td>The best way to travel from Tel-Aviv to Jerusa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>winner_model_b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             model_a              model_b  \\\n",
       "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1   53567           koala-13b           gpt-4-0613   \n",
       "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Is it morally right to try to have a certain p...   \n",
       "1  What is the difference between marriage licens...   \n",
       "2  explain function calling. how would you call a...   \n",
       "3  How can I create a test set for a very rare ca...   \n",
       "4  What is the best way to travel from Tel-Aviv t...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  The question of whether it is morally right to...   \n",
       "1  A marriage license is a legal document that al...   \n",
       "2  Function calling is the process of invoking or...   \n",
       "3  Creating a test set for a very rare category c...   \n",
       "4  The best way to travel from Tel Aviv to Jerusa...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  As an AI, I don't have personal beliefs or opi...               1   \n",
       "1  A marriage license and a marriage certificate ...               0   \n",
       "2  Function calling is the process of invoking a ...               0   \n",
       "3  When building a classifier for a very rare cat...               1   \n",
       "4  The best way to travel from Tel-Aviv to Jerusa...               0   \n",
       "\n",
       "   winner_model_b  winner_tie      class_name  class_label  \n",
       "0               0           0  winner_model_a            0  \n",
       "1               1           0  winner_model_b            1  \n",
       "2               0           1      winner_tie            2  \n",
       "3               0           0  winner_model_a            0  \n",
       "4               1           0  winner_model_b            1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Take the first prompt and its associated response\n",
    "df_train[\"prompt\"] = df_train.prompt.map(lambda x: eval(x)[0])\n",
    "df_train[\"response_a\"] = df_train.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "df_train[\"response_b\"] = df_train.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# Label conversion\n",
    "df_train[\"class_name\"] = df_train[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\n",
    "df_train[\"class_label\"] = df_train[\"class_name\"].map({\"winner_model_a\": 0, \"winner_model_b\": 1, \"winner_tie\": 2})\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Êñ∞Â¢û‰∏ÄÂÄãÊ¨Ñ‰Ωç pairsÔºålistÂ≠òÊîæÂÖ©ÁµÑ prompt-response pair(string)\n",
    "\n",
    "def make_pairs(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        prompt = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_a = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_b = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    row['pairs'] = [\n",
    "    f\"[PROMPT] {prompt} [SEP] [RESPONSE_A] {response_a}\",  # Response from Model A\n",
    "    f\"[PROMPT] {prompt} [SEP] [RESPONSE_B] {response_b}\"  # Response from Model B\n",
    "]\n",
    "    return row\n",
    "\n",
    "df_train = df_train.apply(make_pairs, axis=1)\n",
    "df_test = df_test.apply(make_pairs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.112531,
     "end_time": "2024-06-03T17:02:36.056818",
     "exception": false,
     "start_time": "2024-06-03T17:02:35.944287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>encode_fail</th>\n",
       "      <th>pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>[\"I have three oranges today, I ate an orange ...</td>\n",
       "      <td>[\"You have two oranges today.\"]</td>\n",
       "      <td>[\"You still have three oranges. Eating an oran...</td>\n",
       "      <td>False</td>\n",
       "      <td>[[PROMPT] [\"I have three oranges today, I ate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>[\"You are a mediator in a heated political deb...</td>\n",
       "      <td>[\"Thank you for sharing the details of the sit...</td>\n",
       "      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[[PROMPT] [\"You are a mediator in a heated pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>[\"How to initialize the classification head wh...</td>\n",
       "      <td>[\"When you want to initialize the classificati...</td>\n",
       "      <td>[\"To initialize the classification head when p...</td>\n",
       "      <td>False</td>\n",
       "      <td>[[PROMPT] [\"How to initialize the classificati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0   136060  [\"I have three oranges today, I ate an orange ...   \n",
       "1   211333  [\"You are a mediator in a heated political deb...   \n",
       "2  1233961  [\"How to initialize the classification head wh...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                    [\"You have two oranges today.\"]   \n",
       "1  [\"Thank you for sharing the details of the sit...   \n",
       "2  [\"When you want to initialize the classificati...   \n",
       "\n",
       "                                          response_b  encode_fail  \\\n",
       "0  [\"You still have three oranges. Eating an oran...        False   \n",
       "1  [\"Mr Reddy and Ms Blue both have valid points ...        False   \n",
       "2  [\"To initialize the classification head when p...        False   \n",
       "\n",
       "                                               pairs  \n",
       "0  [[PROMPT] [\"I have three oranges today, I ate ...  \n",
       "1  [[PROMPT] [\"You are a mediator in a heated pol...  \n",
       "2  [[PROMPT] [\"How to initialize the classificati...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.779715,
     "end_time": "2024-06-03T17:02:36.885945",
     "exception": false,
     "start_time": "2024-06-03T17:02:36.10623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57477/57477 [00:38<00:00, 1498.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# !pip install datasets transformers\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Âä†ËΩΩ multilingual-e5-large ÁöÑÂàÜËØçÂô®\n",
    "tokenizer = AutoTokenizer.from_pretrained('FacebookAI/roberta-base')\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('/kaggle/input/bert-base-uncased/pytorch/default/1/bert-base-uncased')\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Á¢∫‰øù pairs ÁöÑÊØèÂÄãÂÖÉÁ¥†ÂàÜÂà•ËôïÁêÜ\n",
    "    encoding_a = tokenizer(\n",
    "        [pair[0] for pair in examples['pairs']],  # Âèñ pairs ‰∏≠ÁöÑÁ¨¨‰∏ÄÂÄãÂ≠ó‰∏≤\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512\n",
    "    )\n",
    "    encoding_b = tokenizer(\n",
    "        [pair[1] for pair in examples['pairs']],  # Âèñ pairs ‰∏≠ÁöÑÁ¨¨‰∫åÂÄãÂ≠ó‰∏≤\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'input_ids_a': encoding_a['input_ids'],\n",
    "        'attention_mask_a': encoding_a['attention_mask'],\n",
    "        'input_ids_b': encoding_b['input_ids'],\n",
    "        'attention_mask_b': encoding_b['attention_mask'],\n",
    "        'labels': examples['class_label']\n",
    "    }\n",
    "\n",
    "dataset = Dataset.from_pandas(df_train[['pairs','class_label']])\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016189,
     "end_time": "2024-06-03T17:02:36.919019",
     "exception": false,
     "start_time": "2024-06-03T17:02:36.90283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üçΩÔ∏è | Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 3.390834,
     "end_time": "2024-06-03T17:02:40.326479",
     "exception": false,
     "start_time": "2024-06-03T17:02:36.935645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 145.15 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function_test(examples):\n",
    "    # Á¢∫‰øù pairs ÁöÑÊØèÂÄãÂÖÉÁ¥†ÂàÜÂà•ËôïÁêÜ\n",
    "    encoding_a = tokenizer(\n",
    "        [pair[0] for pair in examples['pairs']],  # Âèñ pairs ‰∏≠ÁöÑÁ¨¨‰∏ÄÂÄãÂ≠ó‰∏≤\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512\n",
    "    )\n",
    "    encoding_b = tokenizer(\n",
    "        [pair[1] for pair in examples['pairs']],  # Âèñ pairs ‰∏≠ÁöÑÁ¨¨‰∫åÂÄãÂ≠ó‰∏≤\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'input_ids_a': encoding_a['input_ids'],\n",
    "        'attention_mask_a': encoding_a['attention_mask'],\n",
    "        'input_ids_b': encoding_b['input_ids'],\n",
    "        'attention_mask_b': encoding_b['attention_mask'],\n",
    "    }\n",
    "\n",
    "dataset_test = Dataset.from_pandas(df_test[['pairs']])\n",
    "tokenized_dataset_test = dataset_test.map(preprocess_function_test, batched=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['pairs', 'input_ids_a', 'attention_mask_a', 'input_ids_b', 'attention_mask_b'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ë®≠ÂÆöÂºµÈáèÊ†ºÂºè\n",
    "tokenized_dataset.set_format(type='torch', columns=['input_ids_a', 'attention_mask_a', 'input_ids_b', 'attention_mask_b', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 1.056025,
     "end_time": "2024-06-03T17:02:41.433464",
     "exception": false,
     "start_time": "2024-06-03T17:02:40.377439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_dataset_test.set_format(type='torch', columns=['input_ids_a', 'attention_mask_a', 'input_ids_b', 'attention_mask_b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 0.024249,
     "end_time": "2024-06-03T17:02:41.510214",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.485965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ÂâµÂª∫ DataLoader\n",
    "batch_size = 8\n",
    "train_dataloader = torch.utils.data.DataLoader(tokenized_dataset, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(tokenized_dataset_test, batch_size=1,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016686,
     "end_time": "2024-06-03T17:02:41.543394",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.526708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.026326,
     "end_time": "2024-06-03T17:02:41.586658",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.560332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BertComparisonModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name='bert-base-uncased'):\n",
    "        super(BertComparisonModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(pretrained_model_name)\n",
    "        self.pooler = nn.Linear(768 * 2, 768)\n",
    "        self.classifier = nn.Linear(768, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        # ÂàÜÂà•ÈÄöÈÅé BERT Ê®°Âûã\n",
    "        output_a = self.bert(input_ids=input_ids_a, attention_mask=attention_mask_a)\n",
    "        output_b = self.bert(input_ids=input_ids_b, attention_mask=attention_mask_b)\n",
    "\n",
    "        # Áç≤Âèñ [CLS] token ÁöÑËº∏Âá∫‰ΩúÁÇ∫Âè•Â≠êÂµåÂÖ•\n",
    "        embedding_a = output_a.last_hidden_state[:, 0, :]  # [batch_size, 768]\n",
    "        embedding_b = output_b.last_hidden_state[:, 0, :]  # [batch_size, 768]\n",
    "\n",
    "        # Â∞áÂÖ©ÂÄãÂè•Â≠êÁöÑÂµåÂÖ•‰∏≤Êé•Ëµ∑‰æÜ\n",
    "        combined_embedding = torch.cat([embedding_a, embedding_b], dim=1) # [batch_size, 768 * 2]\n",
    "        pooled_embedding = torch.tanh(self.pooler(combined_embedding)) # [batch_size, 768]\n",
    "\n",
    "        # ÈÄöÈÅéÂàÜÈ°ûÂô®Áç≤ÂèñÊúÄÁµÇÁöÑÈ†êÊ∏¨ÁµêÊûú\n",
    "        logits = self.classifier(pooled_embedding) # [batch_size, 3]\n",
    "        probs = self.softmax(logits)\n",
    "\n",
    "        return logits, probs\n",
    "    \n",
    "    def predict(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        logits, probs = self.forward(input_ids_a, attention_mask_a, input_ids_b, attention_mask_b)\n",
    "        return probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultilingualE5ComparisonModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name='intfloat/multilingual-e5-small'):\n",
    "        super(MultilingualE5ComparisonModel, self).__init__()\n",
    "        # ‰ΩøÁî® AutoModel Âä†ËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°Âûã\n",
    "        self.model = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        \n",
    "        # Âä®ÊÄÅËé∑ÂèñÊ®°ÂûãÁöÑ hidden size\n",
    "        hidden_size = self.model.config.hidden_size\n",
    "        \n",
    "        # Ê†πÊçÆÊ®°ÂûãÁöÑ hidden size ÂàõÂª∫Ê±†ÂåñÂíåÂàÜÁ±ªÂ±Ç\n",
    "        self.pooler = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        # ÂàÜÂà´ÈÄöËøáÊ®°Âûã\n",
    "        output_a = self.model(input_ids=input_ids_a, attention_mask=attention_mask_a)\n",
    "        output_b = self.model(input_ids=input_ids_b, attention_mask=attention_mask_b)\n",
    "        \n",
    "        # Ëé∑Âèñ [CLS] token ÁöÑËæìÂá∫‰Ωú‰∏∫Âè•Â≠êÂµåÂÖ•\n",
    "        embedding_a = output_a.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        embedding_b = output_b.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        # Â∞Ü‰∏§‰∏™Âè•Â≠êÁöÑÂµåÂÖ•‰∏≤Êé•Ëµ∑Êù•\n",
    "        combined_embedding = torch.cat([embedding_a, embedding_b], dim=1)  # [batch_size, hidden_size * 2]\n",
    "        pooled_embedding = torch.tanh(self.pooler(combined_embedding))  # [batch_size, hidden_size]\n",
    "        \n",
    "        # ÈÄöËøáÂàÜÁ±ªÂô®Ëé∑ÂèñÊúÄÁªàÁöÑÈ¢ÑÊµãÁªìÊûú\n",
    "        logits = self.classifier(pooled_embedding)  # [batch_size, 3]\n",
    "        probs = self.softmax(logits)\n",
    "        return logits, probs\n",
    "    \n",
    "    def predict(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        with torch.no_grad():\n",
    "            logits, probs = self.forward(input_ids_a, attention_mask_a, input_ids_b, attention_mask_b)\n",
    "            return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ROBERTAComparisonModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_name='FacebookAI/roberta-base'):\n",
    "        super(ROBERTAComparisonModel, self).__init__()\n",
    "        # ‰ΩøÁî® AutoModel Âä†ËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°Âûã\n",
    "        self.model = AutoModel.from_pretrained(pretrained_model_name)\n",
    "        \n",
    "        # Âä®ÊÄÅËé∑ÂèñÊ®°ÂûãÁöÑ hidden size\n",
    "        hidden_size = self.model.config.hidden_size\n",
    "        \n",
    "        # Ê†πÊçÆÊ®°ÂûãÁöÑ hidden size ÂàõÂª∫Ê±†ÂåñÂíåÂàÜÁ±ªÂ±Ç\n",
    "        self.pooler = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        # ÂàÜÂà´ÈÄöËøáÊ®°Âûã\n",
    "        output_a = self.model(input_ids=input_ids_a, attention_mask=attention_mask_a)\n",
    "        output_b = self.model(input_ids=input_ids_b, attention_mask=attention_mask_b)\n",
    "        \n",
    "        # Ëé∑Âèñ [CLS] token ÁöÑËæìÂá∫‰Ωú‰∏∫Âè•Â≠êÂµåÂÖ•\n",
    "        embedding_a = output_a.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        embedding_b = output_b.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "        \n",
    "        # Â∞Ü‰∏§‰∏™Âè•Â≠êÁöÑÂµåÂÖ•‰∏≤Êé•Ëµ∑Êù•\n",
    "        combined_embedding = torch.cat([embedding_a, embedding_b], dim=1)  # [batch_size, hidden_size * 2]\n",
    "        pooled_embedding = torch.tanh(self.pooler(combined_embedding))  # [batch_size, hidden_size]\n",
    "        \n",
    "        # ÈÄöËøáÂàÜÁ±ªÂô®Ëé∑ÂèñÊúÄÁªàÁöÑÈ¢ÑÊµãÁªìÊûú\n",
    "        logits = self.classifier(pooled_embedding)  # [batch_size, 3]\n",
    "        probs = self.softmax(logits)\n",
    "        return logits, probs\n",
    "    \n",
    "    def predict(self, input_ids_a, attention_mask_a, input_ids_b, attention_mask_b):\n",
    "        with torch.no_grad():\n",
    "            logits, probs = self.forward(input_ids_a, attention_mask_a, input_ids_b, attention_mask_b)\n",
    "            return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016559,
     "end_time": "2024-06-03T17:02:41.619713",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.603154",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_kg_hide-input": false,
    "papermill": {
     "duration": 5.308478,
     "end_time": "2024-06-03T17:02:46.944786",
     "exception": false,
     "start_time": "2024-06-03T17:02:41.636308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ROBERTAComparisonModel(pretrained_model_name='FacebookAI/roberta-base')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7185/7185 [46:41<00:00,  2.56batch/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 1.1018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                                                 | 2092/7185 [13:36<32:57,  2.58batch/s, loss=1.07]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ÂÆöÁæ©ÊêçÂ§±ÂáΩÊï∏\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Ë®ìÁ∑¥Ë®≠ÂÆö\n",
    "epochs = 3\n",
    "\n",
    "# ÂÅáË®≠ train_dataloader Â∑≤Á∂ìÂÆöÁæ©\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # ‰ΩøÁî® tqdm ÂåÖË£ù DataLoader\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\", unit=\"batch\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids_a = batch['input_ids_a'].to(device)\n",
    "        attention_mask_a = batch['attention_mask_a'].to(device)\n",
    "        input_ids_b = batch['input_ids_b'].to(device)\n",
    "        attention_mask_b = batch['attention_mask_b'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Ê∏ÖÁ©∫Ê¢ØÂ∫¶\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ÂâçÂêëÂÇ≥Êí≠\n",
    "        logits, probs = model(input_ids_a, attention_mask_a, input_ids_b, attention_mask_b)\n",
    "\n",
    "        # Ë®àÁÆóÊêçÂ§±\n",
    "        loss = loss_fn(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Êõ¥Êñ∞ÈÄ≤Â∫¶Ê¢ùÁöÑÊèèËø∞\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # ÂèçÂêëÂÇ≥Êí≠ËàáÊõ¥Êñ∞ÂèÉÊï∏\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.051632,
     "end_time": "2024-06-03T17:02:55.909391",
     "exception": false,
     "start_time": "2024-06-03T17:02:55.857759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"best_model.weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.754041,
     "end_time": "2024-06-03T19:18:30.53816",
     "exception": false,
     "start_time": "2024-06-03T19:18:29.784119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üß™ | Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ROBERTAComparisonModel(pretrained_model_name='FacebookAI/roberta-base')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.weights.pt\"))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 6.510153,
     "end_time": "2024-06-03T19:18:39.767367",
     "exception": false,
     "start_time": "2024-06-03T19:18:33.257214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction loop\n",
    "model.eval()  # Set model to evaluation mode\n",
    "test_preds = []  # To store predictions\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input_ids_a = batch['input_ids_a'].to(device)\n",
    "        attention_mask_a = batch['attention_mask_a'].to(device)\n",
    "        input_ids_b = batch['input_ids_b'].to(device)\n",
    "        attention_mask_b = batch['attention_mask_b'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits, probs = model(\n",
    "            input_ids_a=input_ids_a,\n",
    "            attention_mask_a=attention_mask_a,\n",
    "            input_ids_b=input_ids_b,\n",
    "            attention_mask_b=attention_mask_b\n",
    "        )\n",
    "        print(probs)\n",
    "        # Predicted class\n",
    "        preds = probs\n",
    "        test_preds.extend(preds.cpu().numpy())  # Collect predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.768879,
     "end_time": "2024-06-03T19:18:41.329256",
     "exception": false,
     "start_time": "2024-06-03T19:18:40.560377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üì¨ | Submission\n",
    "\n",
    "Following code will prepare the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.751809,
     "end_time": "2024-06-03T19:18:42.839827",
     "exception": false,
     "start_time": "2024-06-03T19:18:42.088018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the class names directly\n",
    "label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n",
    "class_names = list(label2name.values())\n",
    "\n",
    "# Convert predictions to a list\n",
    "test_preds = np.array(test_preds).tolist()\n",
    "\n",
    "# Assuming `df_test` has an \"id\" column\n",
    "df_test = pd.DataFrame({'id': [1, 2, 3]})  # Example DataFrame for demonstration\n",
    "\n",
    "# Save results\n",
    "sub_df = df_test[[\"id\"]].copy()\n",
    "sub_df[\"winner_model_a\"] = [pred[0] for pred in test_preds]\n",
    "sub_df[\"winner_model_b\"] = [pred[1] for pred in test_preds]\n",
    "sub_df[\"winner_tie\"] = [pred[2] for pred in test_preds]\n",
    "sub_df.to_csv(\"submission.csv\", index=False)  # Save to CSV\n",
    "\n",
    "# Display the first few rows of the saved DataFrame\n",
    "print(sub_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.740084,
     "end_time": "2024-06-03T19:18:44.386408",
     "exception": false,
     "start_time": "2024-06-03T19:18:43.646324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üî≠ | Future Directions\n",
    "\n",
    "In this notebook, we've achieved a good score with a small model and modest token length. But there's plenty of room to improve. Here's how:\n",
    "\n",
    "1. Try bigger models like `Deberta-Base` or `Deberta-Small`, or even LLMs like `Gemma`.\n",
    "2. Increase max token length to reduce loss of data.\n",
    "3. Use a five-fold cross-validation and ensemble to make the model robust and get better scores.\n",
    "4. Add augmentation like shuffling response orders for more robust performance.\n",
    "5. Train for more epochs.\n",
    "6. Tune the learning rate scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.830152,
     "end_time": "2024-06-03T19:18:45.950588",
     "exception": false,
     "start_time": "2024-06-03T19:18:45.120436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# üìå | Reference\n",
    "\n",
    "* [LLM Science Exam: KerasCore + KerasNLP [TPU]](https://www.kaggle.com/code/awsaf49/llm-science-exam-kerascore-kerasnlp-tpu)\n",
    "* [AES 2.0: KerasNLP Starter](https://www.kaggle.com/code/awsaf49/aes-2-0-kerasnlp-starter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4686,
     "sourceId": 6065,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4687,
     "sourceId": 6066,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 133071,
     "modelInstanceId": 108753,
     "sourceId": 129073,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8265.260972,
   "end_time": "2024-06-03T19:18:50.009067",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-03T17:01:04.748095",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
